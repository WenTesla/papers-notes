# MAGIC：基于掩码图表示学习的高级持续性威胁检测

以往的研究存在一些缺点：（1）需要包含攻击的数据以及APTs的先验知识，（2）无法提取起源图中蕴含的丰富上下文信息，（3）由于过高的计算开销和内存消耗而变得不切实际。

## 设计

![img](https://cdn.xljsci.com/literature/112636123/page4/8iuhpc.png)

### ==溯源图构建==

#### log Parsing 日志解析

log Parsing 是 MAGIC 中来源图构建的第一步，主要流程如下：首先解析每条日志条目，提取系统实体以及实体间的系统交互；接着以系统实体为节点、交互为边，构建原型来源图；然后提取节点和边的分类信息，对于提供实体和交互标签的简单日志格式，直接使用这些标签，而对于提供实体和交互复杂属性的格式，则应用多标签哈希（如 xxhash）将属性转换为标签。

#### Initial Embedding（初始嵌入）

1. **转化为固定大小特征向量**：在该阶段，将节点和边的标签转化为维度为 d 的固定大小特征向量，这个 d 是图表示模块的隐藏维度 。
2. **使用查找嵌入**：采用查找嵌入的方式，建立节点 / 边标签与 d 维特征向量之间的一对一映射 。这种映射关系使得每个标签都能唯一对应一个特定的特征向量，方便模型进行后续的计算和处理。例如，在图 3 的（I）和（II）中，进程 a和 b 由于共享相同的标签，所以被映射到相同的特征向量；而a和c具有不同标签的节点，则被嵌入到不同的特征向量中。
3. **映射受数据源影响**：唯一节点 / 边标签的可能数量由数据源（即审计日志格式）决定 。这意味着不同的审计日志格式会导致不同数量的唯一标签，进而影响查找嵌入的具体映射关系。在这种情况下，查找嵌入在直推式设置下工作，它不需要为未见标签学习嵌入。因为它是基于已有的标签和对应的特征向量进行映射，对于训练过程中未出现的标签，不进行额外的嵌入学习 。

#### Noise Reduction（噪声 reduction）：

- **合并节点对间的多条边**：由于图表示模块期望的输入是简单图，因此需要对节点对之间的多条边进行合并。**若一对节点间存在多条相同标签（且具有相同初始嵌入）的边，会移除冗余边，仅保留一条；对于一对节点间不同标签的边，则保留这些边并将其合并为一条最终边。**
- **计算合并后边的初始嵌入**：**合并后，最终边的初始嵌入通过对剩余边的初始嵌入取平均值得到。**
- **示例说明**：如图 3（II 和 III）所示，在 a和 c 之间有 3 条 “read” 交互边和 2 条 “write” 交互边，首先将相同标签的边分别合并为 1 条，即 1 条 “read” 边和 1 条 “write” 边，然后将这两条边合并为一条边，其初始嵌入为这两条边初始嵌入的平均值

<img src="https://cdn.xljsci.com/literature/112636123/page5/g0a2xn.png" alt="img" style="zoom: 67%;" />

### 图表示

#### Feature Masking 特征掩码

在训练图表示模块前对节点进行掩码操作，是为了让图掩码自编码器能通过重构这些节点来完成训练。具体来说，会随机选择占一定比例的节点作为掩码节点，将这些节点的初始嵌入替换为特殊的掩码标记$x_{mask}$，以此掩盖节点的原始信息
$$
emb_n =\left\{
                        \begin{aligned}
                       x_n, n \notin  eN \\
                       x_{mask}, n \in eN 
                        \end{aligned}
                \right.
$$

#### 图编码器

使用GAT

#### 图解码器

