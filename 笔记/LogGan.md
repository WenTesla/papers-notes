# LogGAN：一种基于排列事件建模的用于异常检测的日志级别生成对抗网络

## 分类

### 监督

有监督异常检测基于两个普遍假设：（1）正常和异常实例的标签是可获取的；（2）在给定的特征空间中，正常和异常实例是可区分的。

### 半监督

在给定的特征空间中，正常样本会紧密聚集，而异常样本则远离正常样本形成的集群（Chandola 等人，2009）。半监督模型的典型代表是基于最近邻的技术，这类技术可分为**（1）基于距离的邻域方法和（2）基于密度的邻域方法。**

### 无监督

LogCluster 旨在利用知识库对历史日志和新生成的日志进行聚类，工程师只需区分每个聚类中的部分日志（即事件），就能识别出同一聚类中的异常类型。因此，使用 LogCluster 无需获取日志的标签，日志之间的相似度反而更为关键。

## 设计

日志解析器：该模块用于将非结构化日志解析为结构化日志（或事件），这些结构化日志（或事件）被视为后续基于机器学习技术的最小单元。

对抗学习：该模块用于基于从结构化日志中提取的时间戳、签名和属性，训练基于长短期记忆网络（LSTM）的异常检测模型。

异常检测：该模块使用基于长短期记忆网络（LSTM）的模型来检测和诊断异常情况，并根据新生成的日志和用户反馈对模型进行增量更新。

### 日志解析

<img src="https://cdn.xljsci.com/literature/168145204/page5/z01odk.png" alt="img" style="zoom:67%;" />

### GAN

生成对抗网络将机器学习问题视为两个模型（即生成器和判别器）之间的博弈（古德费洛等人，2014年）。**生成器（G）捕捉真实样本的分布，并生成在特征表示上与真实样本相似的可信样本，而判别器（D）则试图识别即将到来的样本是真实的还是合成的，以提高G生成的样本质量。**这个迭代过程不断重复，直到G和D都收敛，此时G就能生成 “真实” 的样本。经过充分训练的G可以捕捉异常数据的分布。

**LogGan能够独立生成每个后续事件的连续概率，而非使用 softmax 层输出所有事件的概率分布**

具体来说，给定从解析后的系统日志中观察到的一组时序事件*S*={*e*(1),*e*(2),...,*e*(*s*)}，以及一组事件*E*={e~1~,e~2~,...,em*}（其中*e~j~表示第j个事件的签名），LogGAN 的任务是基于集合C={c~1~,c~2~,...,c~n~}中的上下文组合（其中c~i~表示第*i*个组合），**预测后续事件（即日志）是正常还是异常**。

对于生成器，我们将随机噪声 z 和一个组合 c~i~ 作为 LSTM 的输入，其输出是一个 m 维向量，该向量表示集合 E 中每个事件的独立发生概率。对于判别器，我们将组合 c~i~ 作为输入，并将独立发生概率的 m 维向量作为 LSTM 的参数，其输出是在上下文组合 c~i~ 下该 m 维向量是真实样本还是虚假样本。 

> 关键在于 LogGAN 的计算方式是 “为每个事件单独生成连续概率”，而非通过 softmax 层强制让所有概率 “归一化”（即不是先计算整体分布再分配概率）。这种方式更灵活，能避免 softmax 层对稀有事件（如异常事件）的概率压缩问题，更适合系统日志中离散事件的预测场景。

<img src="https://oss.xljsci.com//literature/168145204/page0/1753593895300.png" alt="img" style="zoom:67%;" />

LogGAN 通过生成器与判别器的 “对抗博弈” 实现优化：**生成器试图模仿真实事件分布生成假样本，判别器则努力区分真假样本**。最终生成器能够捕捉正常事件的规律，当新日志与生成器预测的正常模式偏差较大时，即被判定为异常。这种设计缓解了数据不平衡问题（异常样本少），同时通过小批量训练提高了效率。

**生成器生成的假样本既包含模拟的正常事件，也包含模拟的异常事件。**

### 排序时间建模

基于滑动窗口的模式有缺陷。

基于模式的训练模式，会收集训练集中特定模式后可能出现的所有后续事件（包括正常和异常），并将 “模式与后续事件的组合” 作为训练样本。具体来说，一个模式的标签是一个 n 维向量：

- 观测到的正常事件对应位置设为 1；
- 观测到的异常事件和未观测到的事件对应位置设为 0。

**LSTM对时间序列非常敏感。**

置换事件建模通过 “基于最频繁模式构建基线，再扩展到其他模式” 的方式，生成合理的事件序列变体，具体分为两步：

**1. 以最频繁模式的后续事件作为基线**

在训练集中，若某一事件模式（如`(203,186,213)`）出现频率最高（文中提到 “出现 1+40 次”），则将其后续事件作为**所有置换模式的基线**。

- 例如，假设模式`(203,186,213)`的后续事件是`e_base`（如 “正常断开连接”），那么`e_base`会被视为其他置换模式的参考基准。

**2. 为其他模式的置换序列补充后续事件**

对于训练集中出现频率较低的其他模式（如`(203,213,186)`和`(186,203,213)`），其后续事件由两部分组成：

- **自身观测到的后续事件**：该模式在训练数据中实际出现过的后续事件（如`(203,213,186)`的后续事件`e1`）。
- **最频繁模式与当前模式的差异事件**：计算最频繁模式的后续事件`e_base`与当前模式观测到的后续事件`e_observed`的 “差异”（如文中的 “3” 和 “349”，可理解为事件 ID 的差值或特征距离），并将这一差异对应的事件补充为当前置换模式的后续事件

## 实验



<img src="https://cdn.xljsci.com/literature/168145204/page10/gbi615.png" alt="img" style="zoom:50%;" />

### 消融实验

<img src="https://cdn.xljsci.com/literature/168145204/page12/kht0j6.png" alt="img" style="zoom:50%;" />